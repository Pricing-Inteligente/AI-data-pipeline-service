{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34ae364b",
   "metadata": {},
   "source": [
    "## MODELOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1067a3e9",
   "metadata": {},
   "source": [
    "#### PlanTL-GOB-ES/roberta-base-bne-sqac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b6a234c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\santi\\appdata\\roaming\\python\\python39\\site-packages (4.52.4)\n",
      "Requirement already satisfied: torch in c:\\users\\santi\\appdata\\roaming\\python\\python39\\site-packages (2.7.1)\n",
      "Requirement already satisfied: tqdm in c:\\python39\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\santi\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\python39\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\santi\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\santi\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\santi\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (0.33.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\santi\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: requests in c:\\python39\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\santi\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\santi\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\santi\\appdata\\roaming\\python\\python39\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\santi\\appdata\\roaming\\python\\python39\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\santi\\appdata\\roaming\\python\\python39\\site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\santi\\appdata\\roaming\\python\\python39\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\santi\\appdata\\roaming\\python\\python39\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\santi\\appdata\\roaming\\python\\python39\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\python39\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\santi\\appdata\\roaming\\python\\python39\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\santi\\appdata\\roaming\\python\\python39\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python39\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python39\\lib\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\santi\\appdata\\roaming\\python\\python39\\site-packages (from requests->transformers) (3.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -harset-normalizer (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -harset-normalizer (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -harset-normalizer (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -harset-normalizer (c:\\python39\\lib\\site-packages)\n",
      "WARNING: You are using pip version 22.0.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers torch tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bbc83e",
   "metadata": {},
   "source": [
    "CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54251b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import deque\n",
    "from datetime import datetime as dt\n",
    "import json\n",
    "import re\n",
    "import pprint\n",
    "\n",
    "# Par√°metros con preguntas\n",
    "QUESTIONS = {\n",
    "    \"precio\": \"¬øCu√°l es el precio del producto?\",\n",
    "    \"nombre\": \"¬øCu√°l es el nombre del producto?\",\n",
    "    \"marca\": \"¬øCu√°l es la marca del producto?\",\n",
    "    \"unidad\": \"¬øEn qu√© unidad se vende el producto?\",\n",
    "    \"precio_unidad_basica\": \"¬øCu√°l es el precio por unidad b√°sica?\",\n",
    "}\n",
    "\n",
    "MAX_ATTEMPTS = 5\n",
    "NEED_MATCHES = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1003be5",
   "metadata": {},
   "source": [
    "CARGA DEL MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "edd3ed2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "MODEL_ID = \"PlanTL-GOB-ES/roberta-base-bne-sqac\"\n",
    "\n",
    "def load_qa_model(model_id: str = MODEL_ID):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "    model = AutoModelForQuestionAnswering.from_pretrained(model_id, device_map=\"auto\")\n",
    "    return pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "qa_pipe = load_qa_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d17c464",
   "metadata": {},
   "source": [
    "LIMPIEZA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b068c1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import html as html_lib\n",
    "\n",
    "TAG_RE = re.compile(r\"<[^>]+>\")\n",
    "SCRIPT_RE = re.compile(r\"<(script|style).*?>.*?</\\1>\", re.I | re.S)\n",
    "WS_RE = re.compile(r\"\\s+\")\n",
    "BODY_RE = re.compile(r\"<body[^>]*>(.*?)</body>\", re.I | re.S)\n",
    "\n",
    "def extract_body_content(raw_html: str):\n",
    "    match = BODY_RE.search(raw_html)\n",
    "    return match.group(1).strip() if match else raw_html\n",
    "\n",
    "def strip_html(raw: str) -> str:\n",
    "    raw = SCRIPT_RE.sub(\" \", raw)\n",
    "    raw = TAG_RE.sub(\" \", raw)\n",
    "    return WS_RE.sub(\" \", html_lib.unescape(raw)).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bf1ea2",
   "metadata": {},
   "source": [
    "PREGUNTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "99bd7405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_model(context: str):\n",
    "    \"\"\"Devuelve un dict con todas las respuestas de QA\"\"\"\n",
    "    respuestas = {}\n",
    "    for key, pregunta in QUESTIONS.items():\n",
    "        result = qa_pipe(question=pregunta, context=context)\n",
    "        answer = result.get(\"answer\", \"\").strip()\n",
    "        if not answer or answer.lower() in {\"no\", \"ninguno\"}:\n",
    "            answer = \"NA\"\n",
    "        respuestas[key] = answer\n",
    "        \n",
    "    if any(value == \"NA\" for value in respuestas.values()):\n",
    "        return None\n",
    "    return respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88db54c",
   "metadata": {},
   "source": [
    "FORMATEAR (HTML - TXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b2d7e00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_path = Path(\"data/processed/Brazil/1_extracted.txt\")\n",
    "html_path = Path(\"data/raw/Mexico/Alsuper/Arroz/Verde Valle/1.html\")\n",
    "\n",
    "def procesar_archivos_reales(url:str, retail: str, country: str):\n",
    "    resultado_final = {\n",
    "        \"HTML\": {},\n",
    "        \"TXT\": {}\n",
    "    }\n",
    "\n",
    "    # üì• Procesar HTML\n",
    "    if html_path.exists():\n",
    "        raw_html = html_path.read_text(errors=\"ignore\")\n",
    "        html_content = extract_body_content(raw_html)\n",
    "        context = strip_html(html_content)\n",
    "\n",
    "        respuestas = deque(maxlen=NEED_MATCHES)\n",
    "        for intento in range(1, MAX_ATTEMPTS + 1):\n",
    "            result = ask_model(context)\n",
    "            if not result:\n",
    "                print(f\"‚ùå HTML intento {intento} fallido.\")\n",
    "                continue\n",
    "\n",
    "            result[\"url\"] = url\n",
    "            result[\"retail\"] = retail\n",
    "            result[\"pais\"] = country\n",
    "            respuestas.append(json.dumps(result, sort_keys=True))\n",
    "\n",
    "            if len(respuestas) == NEED_MATCHES and len(set(respuestas)) == 1:\n",
    "                print(f\"‚úÖ HTML: respuesta estable (intento {intento})\")\n",
    "                key = result[\"nombre\"].lower().replace(\" \", \"_\")\n",
    "                resultado_final[\"HTML\"][key] = result\n",
    "                break\n",
    "    else:\n",
    "        print(\"‚ùå HTML no encontrado:\", html_path)\n",
    "\n",
    "    # üìù Procesar TXT\n",
    "    if text_path.exists():\n",
    "        context = text_path.read_text(errors=\"ignore\").strip()\n",
    "\n",
    "        respuestas = deque(maxlen=NEED_MATCHES)\n",
    "        for intento in range(1, MAX_ATTEMPTS + 1):\n",
    "            result = ask_model(context)\n",
    "            if not result:\n",
    "                print(f\"‚ùå TXT intento {intento} fallido.\")\n",
    "                continue\n",
    "\n",
    "            result[\"url\"] = url\n",
    "            result[\"retail\"] = retail\n",
    "            result[\"pais\"] = country\n",
    "            respuestas.append(json.dumps(result, sort_keys=True))\n",
    "\n",
    "            if len(respuestas) == NEED_MATCHES and len(set(respuestas)) == 1:\n",
    "                print(f\"‚úÖ TXT: respuesta estable (intento {intento})\")\n",
    "                key = result[\"nombre\"].lower().replace(\" \", \"_\")\n",
    "                resultado_final[\"TXT\"][key] = result\n",
    "                break\n",
    "    else:\n",
    "        print(\"‚ùå TXT no encontrado:\", text_path)\n",
    "\n",
    "    # Mostrar resultados\n",
    "    print(\"\\nüîç Resultado final:\\n\")\n",
    "    pprint.pprint(resultado_final)\n",
    "\n",
    "    return resultado_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468662c9",
   "metadata": {},
   "source": [
    "HTML (o texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "75dcd26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ HTML: respuesta estable (intento 2)\n",
      "‚úÖ TXT: respuesta estable (intento 2)\n",
      "\n",
      "üîç Resultado final:\n",
      "\n",
      "{'HTML': {'arroz_salvaje': {'marca': 'Arroz Marca Verde Valle',\n",
      "                            'nombre': 'Arroz Salvaje',\n",
      "                            'pais': 'Mexico',\n",
      "                            'precio': '252246 $38.90',\n",
      "                            'precio_unidad_basica': '252246 $38.90',\n",
      "                            'retail': 'Alsuper',\n",
      "                            'unidad': '252246 $38.90',\n",
      "                            'url': 'Esto es una url'}},\n",
      " 'TXT': {'arroz_s√∫per_extra_verde_valle': {'marca': 'Verde Valle',\n",
      "                                           'nombre': 'Arroz s√∫per extra Verde '\n",
      "                                                     'Valle',\n",
      "                                           'pais': 'Mexico',\n",
      "                                           'precio': '$31.90',\n",
      "                                           'precio_unidad_basica': '252246\\n'\n",
      "                                                                   '$38.90',\n",
      "                                           'retail': 'Alsuper',\n",
      "                                           'unidad': '252246',\n",
      "                                           'url': 'Esto es una url'}}}\n"
     ]
    }
   ],
   "source": [
    "productos = procesar_archivos_reales(url= \"Esto es una url\", retail=\"Alsuper\", country=\"Mexico\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217f42fe",
   "metadata": {},
   "source": [
    "#### llama\\phi-2.Q4_K_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2452e549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\santi\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers torch --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59c44e9",
   "metadata": {},
   "source": [
    "Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd48d579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì§ RESPUESTA DEL MODELO:\n",
      "Instrucci√≥n: Extrae la siguiente informaci√≥n del Texto del producto: Tipo de alimento, Precio, Moneda, Marca, Cantidad, Unidad. Responde √∫nicamente con el formato: \"Tipo de alimento, Precio, Moneda, Marca, Cantidad, Unidad\".\n",
      "\n",
      "Ejemplo 1:\n",
      "Texto: Marca: Bimbo COP $7.850 (COP $15.70 / gramo)El Pan Tajado Bimbo Artesano es la elecci√≥n perfecta para quienes buscan un sabor aut√©ntico y una textura inigualable. Ideal para toda la familia.Presentaci√≥n en bolsa de 500 gramos.Unidad de Venta: Bolsa 500g\n",
      "Respuesta: Pan, 7850, COP, Bimbo, 500, gramos\n",
      "###\n",
      "\n",
      "Ejemplo 2:\n",
      "Texto: Consume leche Alpura COP $1800.550 La Leche Entera Alpura es fresca y nutritiva, ideal para toda la familia. Presentaci√≥n en botella de 1 litro. Unidad de Venta: Botella 1L\n",
      "Respuesta: Leche, 1800.550, COP, Alpura, 1, litro\n",
      "###\n",
      "\n",
      "Texto: S O S Arroz Precocido 900 g\n",
      "S O S\n",
      "$31.90\n",
      "Referencia: 252246\n",
      "$38.90\n",
      ".\n",
      "Obt√©n un 5% de cashback en todas tus compras en heb.com.mx y nuestra app con la tarjeta de cr√©dito HEB Afirme. Solic√≠tala aqu√≠\n",
      "M√©todos de entrega\n",
      "Pick&Go\n",
      "Delivery\n",
      "| Descripci√≥n Emocional | Arroz s√∫per extra Verde Valle, es un arroz de la variedad grano largo y siendo ideal para todo tipo de platillos, es el m√°s com√∫n en M√©xico y su calidad es ‚ÄúSUPER EXTRA‚Äù ya que contiene m√°s del 95% de granos enteros. |\n",
      "|---|---|\n",
      "| Tipo de producto | Arroz |\n",
      "| Marca | Verde Valle |\n",
      "| Denominaci√≥n/Variedad | S√∫per extra |\n",
      "| Contenido neto | 900 g |\n",
      "| Presentaci√≥n | Bolsa |\n",
      "| Pa√≠s de origen | M√©xico |\n",
      "| Modo de preparaci√≥n | Si desea, antes de cocer el arroz puede freirlo pero no es necesario, para que no se pegue o apelmace basta con seguir las siguientes instrucciones: 1.- Enjuague el arroz con agua limpia y esc√∫chalo. 2.- Ponga en una cacerola 2 1/2 tazas de agua o caldo de pollo, 2 cucharadas de aceite o mantequilla y sal o consom√© al gusto. Espera a que hierva. 3.- Cuando el agua hierva agregue 1 taza de arroz (previamente enjuagado), tape y deje a fuego lento por aproximadamente 25 minutos o hasta que se consuma el l√≠quido |\n",
      "| Advertencias de almacenamiento | Mant√©ngase en un lugar seco y fresco. Una vez abierto mantenga el envase cerrado |\n",
      "| Ingredientes | Arroz s√∫per extra. Puede contener gluten (trigo) soya |\n",
      "| Al√©rgenos declarados | Gluten, Trigo, Soya |\n",
      "| Tama√±o del grano | Grano largo |\n",
      "|---|---|\n",
      "| Listo para consumir | No |\n",
      "| Energ√≠a por 100 g | 124.7 Kcal |\n",
      "| Prote√≠nas totales por 100 g | 2.7 g |\n",
      "| Grasas totales por 100 g | 0.3 g |\n",
      "| Carbohidratos totales por 100 g | 27.8 g |\n",
      "| Az√∫cares totales por 100 g | 0.1 g |\n",
      "| Sodio por 100 g | 1 mg |\n",
      "Respuesta:  \"Arroz s√∫per extra, es un arroz de granos enteros y siendo la m√°s com√∫n en M√©xico, tiene su calidad ‚ÄúSUPER EXTRA‚Äù ya que contiene m√°s del 95% de grandes. La preparaci√≥n simple seguir√°: \n",
      "1.- Enjuagate el arroz con agua limpia y escucha. \n",
      "2.- Ponga en una cacerola 2 1/2 tazas de agua o caldo de pollo, 2 cucharadas de aceite or mantequilla y sal o consom√© al gusto. Espera a que hierva. \n",
      "3.- Cuando el agua hierva agregue un taza del arroz (que fue enjuagado) tape y deja a fuego lento por aproximadamente 25 minutos o hasta que se consuma el l√≠quido.\"|\n",
      "###\n",
      "Ejemplo  3:\n",
      "Texto: S O S Arroz —Å –æ–±—É—á–∞—Ç–µ–ª—å–Ω–æ–≥–æ —Ä—É–∫–∏\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "LLAMA_CLI_PATH = Path(r\"C:\\Users\\santi\\AppData\\Local\\Microsoft\\WinGet\\Packages\\ggml.llamacpp_Microsoft.Winget.Source_8wekyb3d8bbwe\\llama-cli.exe\")\n",
    "MODEL_PATH = Path(r\"models/phi-2.Q5_K_S.gguf\")\n",
    "\n",
    "try:\n",
    "    with open(r'data/raw-cleaned/Mexico/HEB/Arroz/Verde Valle/texto_producto.txt', 'r', encoding='utf-8') as file:\n",
    "        texto_producto_actual = file.read() # Lee el contenido del archivo texto_producto.txt\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: El archivo 'texto_producto.txt' no se encontr√≥. Aseg√∫rate de que est√© en la misma carpeta.\")\n",
    "    texto_producto_actual = \"\"\n",
    "\n",
    "try:\n",
    "    with open('prompt.txt', 'r', encoding='utf-8') as file:\n",
    "        prompt_template = file.read() # Lee el contenido del archivo prompt.txt\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: El archivo 'prompt.txt' no se encontr√≥. Aseg√∫rate de que est√© en la misma carpeta.\")\n",
    "    prompt_template = \"\"\n",
    "\n",
    "# Reemplazamos el marcador de posici√≥n en el prompt le√≠do con el contenido del producto.\n",
    "if prompt_template and texto_producto_actual:\n",
    "    prompt_final = prompt_template.format(PRODUCT_TEXT_PLACEHOLDER=texto_producto_actual)\n",
    "else:\n",
    "    prompt_final = \"Error al construir el prompt. Revisa los archivos.\"\n",
    "\n",
    "# Imprimir el prompt para depuraci√≥n\n",
    "#print(\"üì® Prompt generado (con few-shot):\")\n",
    "#print(prompt_final)\n",
    "\n",
    "# üîß Argumentos de generaci√≥n (corregidos, sin espacios extras)\n",
    "args = [\n",
    "    str(LLAMA_CLI_PATH),\n",
    "    \"-m\", str(MODEL_PATH),\n",
    "    \"-p\", prompt_final,\n",
    "    \"-n\", \"256\",\n",
    "    \"--temp\", \"0.5\",\n",
    "    \"--top-p\", \"0.9\",\n",
    "    \"--repeat-penalty\", \"1.2\"\n",
    "]\n",
    "\n",
    "# ‚ñ∂Ô∏è Ejecutar el comando\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        args,\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        check=True,\n",
    "        encoding=\"utf-8\"  # Para manejar acentos y caracteres especiales\n",
    "    )\n",
    "    output = result.stdout.strip()\n",
    "\n",
    "    print(\"üì§ RESPUESTA DEL MODELO:\")\n",
    "    print(output)\n",
    "\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(\"‚ùå ERROR al ejecutar llama-cli:\")\n",
    "    print(e.stderr if e.stderr else str(e))\n",
    "except FileNotFoundError as e:\n",
    "    print(\"‚ùå ERROR: No se encontr√≥ llama-cli.exe o el modelo.\")\n",
    "    print(\"Verifica la ruta a 'llama-cli.exe' y 'phi-2.Q4_K_M.gguf'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4668c3dc",
   "metadata": {},
   "source": [
    "Limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef823be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import html as html_lib\n",
    "\n",
    "\n",
    "# Extracci√≥n de HTML\n",
    "TAG_RE = re.compile(r\"<[^>]+>\")\n",
    "SCRIPT_RE = re.compile(r\"<(script|style).*?>.*?</\\1>\", re.I | re.S)\n",
    "WS_RE = re.compile(r\"\\s+\")\n",
    "BODY_RE = re.compile(r\"<body[^>]*>(.*?)</body>\", re.I | re.S)\n",
    "\n",
    "def extract_body_content(raw_html: str):\n",
    "    match = BODY_RE.search(raw_html)\n",
    "    return match.group(1).strip() if match else raw_html\n",
    "\n",
    "def strip_html(raw: str) -> str:\n",
    "    raw = SCRIPT_RE.sub(\" \", raw)\n",
    "    raw = TAG_RE.sub(\" \", raw)\n",
    "    return WS_RE.sub(\" \", html_lib.unescape(raw)).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d9be6e",
   "metadata": {},
   "source": [
    "PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e398a188",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextStreamer\n",
    "\n",
    "FIELDS = [\"nombre\", \"precio\", \"marca\", \"unidad\", \"precio_unidad_basica\", \"url\"]\n",
    "\n",
    "def construir_prompt(texto_producto: str):\n",
    "    return (\n",
    "        \"<|system|>\\n\"\n",
    "        \"Eres un sistema extractor de informaci√≥n.\\n\"\n",
    "        \"A partir del texto del producto, responde los siguientes campos en este orden separados por comas:\\n\"\n",
    "        f\"{', '.join(FIELDS)}.\\n\"\n",
    "        \"Si falta un valor, escribe NA.\\n\"\n",
    "        \"<|user|>\\n\"\n",
    "        f\"{texto_producto}\\n\"\n",
    "        \"<|assistant|>\\n\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1597af65",
   "metadata": {},
   "source": [
    "MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0736af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def responder_zephyr(prompt: str, max_tokens=256):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_tokens,\n",
    "            streamer=TextStreamer(tokenizer),\n",
    "            do_sample=False,\n",
    "            temperature=0.0\n",
    "        )\n",
    "\n",
    "    respuesta = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return respuesta[len(prompt):].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244f0f47",
   "metadata": {},
   "source": [
    "PARSEAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de91c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_json(respuesta: str):\n",
    "    partes = [p.strip() for p in respuesta.split(\",\")]\n",
    "    if len(partes) != len(FIELDS):\n",
    "        print(\"‚ùå Respuesta incompleta:\", respuesta)\n",
    "        return None\n",
    "    return dict(zip(FIELDS, partes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690c57f2",
   "metadata": {},
   "source": [
    "HTML o TXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744390cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import html as html_lib\n",
    "import re\n",
    "\n",
    "# Helpers HTML\n",
    "def strip_html(raw: str) -> str:\n",
    "    TAG_RE = re.compile(r\"<[^>]+>\")\n",
    "    SCRIPT_RE = re.compile(r\"<(script|style).*?>.*?</\\1>\", re.I | re.S)\n",
    "    WS_RE = re.compile(r\"\\s+\")\n",
    "    raw = SCRIPT_RE.sub(\" \", raw)\n",
    "    raw = TAG_RE.sub(\" \", raw)\n",
    "    return WS_RE.sub(\" \", html_lib.unescape(raw)).strip()\n",
    "\n",
    "def test_archivo(path: Path, tipo: str, retail: str, pais: str):\n",
    "    if not path.exists():\n",
    "        print(f\"‚ùå Archivo no encontrado: {path}\")\n",
    "        return None\n",
    "\n",
    "    texto = path.read_text(errors=\"ignore\")\n",
    "    if path.suffix == \".html\":\n",
    "        texto = strip_html(texto)\n",
    "\n",
    "    prompt = construir_prompt(texto)\n",
    "    respuesta = responder_zephyr(prompt)\n",
    "\n",
    "    print(f\"\\nüì• {tipo.upper()} ‚Üí Prompt output:\\n\", respuesta)\n",
    "\n",
    "    parsed = extraer_json(respuesta)\n",
    "    if parsed:\n",
    "        parsed[\"retail\"] = retail\n",
    "        parsed[\"pais\"] = pais\n",
    "        return parsed\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53947875",
   "metadata": {},
   "source": [
    "PROCESAMIENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b53ae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Archivos de ejemplo\n",
    "html_path = Path(\"data/raw/Mexico/Alsuper/Arroz/Verde Valle/1.html\")\n",
    "text_path = Path(\"data/processed/Brazil/1_extracted.txt\")\n",
    "\n",
    "retail = \"Alsuper\"\n",
    "pais = \"Mexico\"\n",
    "\n",
    "resultado = {\n",
    "    \"HTML\": {},\n",
    "    \"TXT\": {}\n",
    "}\n",
    "\n",
    "html_res = test_archivo(html_path, \"html\", retail, pais)\n",
    "if html_res:\n",
    "    key = html_res[\"nombre\"].lower().replace(\" \", \"_\")\n",
    "    resultado[\"HTML\"][key] = html_res\n",
    "\n",
    "txt_res = test_archivo(text_path, \"txt\", retail, pais)\n",
    "if txt_res:\n",
    "    key = txt_res[\"nombre\"].lower().replace(\" \", \"_\")\n",
    "    resultado[\"TXT\"][key] = txt_res\n",
    "\n",
    "print(\"\\n‚úÖ Resultado final:\")\n",
    "pprint(resultado)\n",
    "\n",
    "output_path = Path(\"data/processed/arroz_mistral.json\")\n",
    "output_path.write_text(json.dumps(resultado, ensure_ascii=False, indent=2))\n",
    "print(f\"üì¶ Guardado en: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bfcc2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7dd4f968",
   "metadata": {},
   "source": [
    "#### LIQUID - Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c5956b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (4.53.2)\n",
      "Requirement already satisfied: accelerate in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (1.9.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (0.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (0.33.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from accelerate) (2.7.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (2025.7.14)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\santi\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (4.53.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (0.33.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (2025.7.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\santi\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers accelerate sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b050b6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (4.53.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (0.33.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\santi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (2025.7.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\santi\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7805bd92",
   "metadata": {},
   "source": [
    "Carga del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787f3220",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The checkpoint you are trying to load has model type `lfm2` but Transformers does not recognize this architecture. This could be because of an issue with the checkpoint, or because your version of Transformers is out of date.\n\nYou can update Transformers with the command `pip install --upgrade transformers`. If this does not work, and the checkpoint is very new, then there may not be a release version that supports this model yet. In this case, you can get the most up-to-date code by installing Transformers from source with the command `pip install git+https://github.com/huggingface/transformers.git`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\models\\auto\\configuration_auto.py:1218\u001b[39m, in \u001b[36mAutoConfig.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m   1217\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1218\u001b[39m     config_class = \u001b[43mCONFIG_MAPPING\u001b[49m\u001b[43m[\u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel_type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m   1219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\models\\auto\\configuration_auto.py:914\u001b[39m, in \u001b[36m_LazyConfigMapping.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._mapping:\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[32m    915\u001b[39m value = \u001b[38;5;28mself\u001b[39m._mapping[key]\n",
      "\u001b[31mKeyError\u001b[39m: 'lfm2'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m MODEL_ID = \u001b[33m\"\u001b[39m\u001b[33mLiquidAI/LFM2-1.2B\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m model = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mMODEL_ID\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Puedes probar bfloat16 si tienes soporte\u001b[39;49;00m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m streamer = TextStreamer(tokenizer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\models\\auto\\auto_factory.py:547\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    544\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mquantization_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    545\u001b[39m     _ = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mquantization_config\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m547\u001b[39m config, kwargs = \u001b[43mAutoConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    548\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    549\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_unused_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[38;5;66;03m# if torch_dtype=auto was passed here, ensure to pass it on\u001b[39;00m\n\u001b[32m    557\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs_orig.get(\u001b[33m\"\u001b[39m\u001b[33mtorch_dtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\models\\auto\\configuration_auto.py:1220\u001b[39m, in \u001b[36mAutoConfig.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m   1218\u001b[39m         config_class = CONFIG_MAPPING[config_dict[\u001b[33m\"\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m\"\u001b[39m]]\n\u001b[32m   1219\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1220\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1221\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe checkpoint you are trying to load has model type `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_dict[\u001b[33m'\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1222\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mbut Transformers does not recognize this architecture. This could be because of an \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1223\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33missue with the checkpoint, or because your version of Transformers is out of date.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1224\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mYou can update Transformers with the command `pip install --upgrade transformers`. If this \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1225\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mdoes not work, and the checkpoint is very new, then there may not be a release version \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1226\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mthat supports this model yet. In this case, you can get the most up-to-date code by installing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1227\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mTransformers from source with the command \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1228\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m`pip install git+https://github.com/huggingface/transformers.git`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1229\u001b[39m         )\n\u001b[32m   1230\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m config_class.from_dict(config_dict, **unused_kwargs)\n\u001b[32m   1231\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1232\u001b[39m     \u001b[38;5;66;03m# Fallback: use pattern matching on the string.\u001b[39;00m\n\u001b[32m   1233\u001b[39m     \u001b[38;5;66;03m# We go from longer names to shorter names to catch roberta before bert (for instance)\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: The checkpoint you are trying to load has model type `lfm2` but Transformers does not recognize this architecture. This could be because of an issue with the checkpoint, or because your version of Transformers is out of date.\n\nYou can update Transformers with the command `pip install --upgrade transformers`. If this does not work, and the checkpoint is very new, then there may not be a release version that supports this model yet. In this case, you can get the most up-to-date code by installing Transformers from source with the command `pip install git+https://github.com/huggingface/transformers.git`"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "MODEL_ID = \"microsoft/phi-2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=torch.float32,  # O usa bfloat16 en GPU\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a69134",
   "metadata": {},
   "source": [
    "Limpieza Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fc5242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import html as html_lib\n",
    "\n",
    "def strip_html(raw: str) -> str:\n",
    "    TAG_RE = re.compile(r\"<[^>]+>\")\n",
    "    SCRIPT_RE = re.compile(r\"<(script|style).*?>.*?</\\1>\", re.I | re.S)\n",
    "    WS_RE = re.compile(r\"\\s+\")\n",
    "\n",
    "    raw = SCRIPT_RE.sub(\" \", raw)\n",
    "    raw = TAG_RE.sub(\" \", raw)\n",
    "    return WS_RE.sub(\" \", html_lib.unescape(raw)).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861b38ee",
   "metadata": {},
   "source": [
    "Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147f0af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAMPOS = [\"nombre\", \"precio\", \"marca\", \"unidad\", \"precio_unidad_basica\"]\n",
    "\n",
    "def construir_prompt(texto: str) -> str:\n",
    "    \n",
    "    return (\n",
    "        f\"A partir del siguiente texto de producto:\\n\\n{texto}\\n\\n\"\n",
    "        f\"Extrae la siguiente informaci√≥n en este orden, separados por comas:\\n\"\n",
    "        f\"{', '.join(CAMPOS)}.\\n\"\n",
    "        \"Si falta un dato, escribe 'NA'. No des explicaciones, solo responde los datos en un rengl√≥n.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c910ca94",
   "metadata": {},
   "source": [
    "Llamado del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf97a381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextStreamer\n",
    "streamer = TextStreamer(tokenizer)\n",
    "\n",
    "prompt = construir_prompt(texto)\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=200,\n",
    "    do_sample=False,\n",
    "    temperature=0.0,\n",
    "    streamer=streamer\n",
    ")\n",
    "\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "respuesta = generated_text[len(prompt):].strip()\n",
    "print(\"\\nüîç Respuesta del modelo:\\n\", respuesta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64371daf",
   "metadata": {},
   "source": [
    "Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ad4d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def respuesta_a_dict(respuesta: str) -> dict | None:\n",
    "    partes = [p.strip() for p in respuesta.split(\",\")]\n",
    "    if len(partes) != len(CAMPOS):\n",
    "        print(\"‚ùå Respuesta inv√°lida o incompleta:\", respuesta)\n",
    "        return None\n",
    "\n",
    "    return dict(zip(CAMPOS, partes))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f72d4e",
   "metadata": {},
   "source": [
    "HTML / TXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d750a440",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def procesar_archivo(path: Path, tipo: str, retail=\"Jumbo\", pais=\"Colombia\") -> dict | None:\n",
    "    if not path.exists():\n",
    "        print(f\"‚ùå Archivo no encontrado: {path}\")\n",
    "        return None\n",
    "\n",
    "    texto = path.read_text(errors=\"ignore\")\n",
    "\n",
    "    if path.suffix == \".html\":\n",
    "        texto = strip_html(texto)\n",
    "\n",
    "    prompt = construir_prompt(texto)\n",
    "    print(f\"\\nüì® Prompt generado ({tipo}):\\n\", prompt)\n",
    "\n",
    "    respuesta = generar_respuesta(prompt)\n",
    "    print(f\"\\nü§ñ Respuesta del modelo:\\n\", respuesta)\n",
    "\n",
    "    info = respuesta_a_dict(respuesta)\n",
    "    if info:\n",
    "        info[\"retail\"] = retail\n",
    "        info[\"pais\"] = pais\n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f3629e",
   "metadata": {},
   "source": [
    "EXECUTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcf9601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "# üöÄ Rutas de tus archivos\n",
    "html_path = Path(\"data/raw/Mexico/Alsuper/Arroz/Verde Valle/1.html\")\n",
    "txt_path = Path(\"data/processed/Brazil/1_extracted.txt\")\n",
    "\n",
    "# üõçÔ∏è Metadatos\n",
    "retail = \"Alsuper\"\n",
    "pais = \"Mexico\"\n",
    "\n",
    "# üì¶ Resultados\n",
    "resultado_final = {\"HTML\": {}, \"TXT\": {}}\n",
    "\n",
    "# üîç HTML\n",
    "res_html = procesar_archivo(html_path, tipo=\"HTML\", retail=retail, pais=pais)\n",
    "if res_html:\n",
    "    key = res_html[\"nombre\"].lower().replace(\" \", \"_\")\n",
    "    resultado_final[\"HTML\"][key] = res_html\n",
    "\n",
    "# ‚úèÔ∏è TXT\n",
    "res_txt = procesar_archivo(txt_path, tipo=\"TXT\", retail=retail, pais=pais)\n",
    "if res_txt:\n",
    "    key = res_txt[\"nombre\"].lower().replace(\" \", \"_\")\n",
    "    resultado_final[\"TXT\"][key] = res_txt\n",
    "\n",
    "# üëÄ Mostrar en pantalla\n",
    "print(\"\\n‚úÖ Resultado final:\")\n",
    "pprint(resultado_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23d5d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "out_path = Path(\"data/processed/productos_extraidos.json\")\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with out_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultado_final, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\nüíæ Resultado guardado en: {out_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
